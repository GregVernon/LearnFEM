---
jupyter: mkernel
---

```{matlab}
%| include: false
clear
setappdata(0, "MKernel_plot_backend", "inline")
setappdata(0, "MKernel_plot_format", "svg")
```

# Finding Polynomial Roots using Linear Algebra
A common problem in mathematics is finding the roots (zeros) of a function.
As we will see shortly, we will want to find roots of *polynomial* functions to aid us in constructing polynomial basis and quadrature schemes.
A common approach to finding roots of functions is to use bracketing methods (e.g., bisection method) or iterative methods based on derivatives (e.g., secant method, Newton's method).
However these methods face many challenges such as how to choose a reasonable starting location, initial bracket bounds, avoiding stagnation, finding multiple roots, duplicate roots, etc.
So how might we avoid these challenges with polynomials?

You may recall from your early linear algebra courses the idea of the *characteristic polynomial* for a matrix.
In short, any square matrix has a characteristic polynomial whose roots are the *eigenvalues* of the matrix.
So what we want to do is to construct a matrix whose characteristic polynomial is the polynomial we want to find the roots of, and then compute the eigenvalues.
For any characteristic polynomial, there are an infinite number of matrices that share the characteristic polynomial (i.e., matrix similarity), however one approach results in constructing what is called the *companion matrix*.

For a *monic polynomial*, that is, a polynomial of the form
$$
p(x) = c_0 x^0 + c_1 x^1 + \cdots c_{n-1} x^{n-1} + c_n x^n \quad \mathrm{where} \ c_n = 1,
$$

```{matlab}
%| output: false
function monic = PolynomialToMonic( polynomial )
  variate = symvar( polynomial );
  if isempty( variate )
    variate = sym( "x" );
  end
  c = fliplr( coeffs( polynomial, "all" ) );
  c = c ./ c(end);
  degree = length( c ) - 1;
  monic = sym( 0 );
  for p = 0 : degree
    monic = monic + c(p+1) * variate^p;
  end
end
```

the companion matrix is defined as:

$$
\Matrix{C} =
\begin{bmatrix}
    0      & 0      & \cdots & 0      & -c_0     \\
    1      & 0      & \cdots & 0      & -c_1     \\
    0      & 1      & \cdots & 0      & -c_2     \\
    \vdots & \vdots & \ddots & \vdots & \vdots   \\
    0      & 0      & \cdots & 1      & -c_{n-1} \\
\end{bmatrix}
$$

```{matlab}
%| output: false
function C = CompanionMatrix( polynomial )
  monic = PolynomialToMonic( polynomial );
  monic_coeffs = fliplr( coeffs( monic, "all" ) );
  degree = length( monic_coeffs ) - 1;
  C = sym( zeros( degree ) );
  for ii = 0 : degree - 1
    row = ii + 1;
    if ii > 0
      C(row, row-1) = 1;
    end
    C(row,end) = -1 * monic_coeffs(ii+1);
  end
end
```

Recall that for a given polynomial we can convert it to a monic polynomial by simply dividing by the leading coefficient.
Let's work through an example.

Consider the polynomial
```{=latex}
\begin{equation}
    p(x) = \frac{x^4}{2} + \frac{x^3}{2} - 6x^2 - 2x + 6
\end{equation}
```

which can also be written in the following form, which makes the coefficients a bit more obvious

```{=latex}
\begin{equation}
    p(x) = \frac{1}{2}x^4 + \frac{1}{2}x^3 - 6x^2 - 2x^1 + 6x^0
\end{equation}
```

The monic polynomial associated with this polynomial is

```{=latex}
\begin{equation}
    p(x) = 1x^4 + 1x^3 - 12x^2 - 4x^1 + 12x^0
\end{equation}
```

and the companion matrix is then

```{=latex}
\begin{equation}
    \Matrix{C} =
    \begin{bmatrix}
        0 & 0 & 0 & -12 \\
        1 & 0 & 0 &   4 \\
        0 & 1 & 0 &  12 \\
        0 & 0 & 1 &  -1 \\
    \end{bmatrix}
\end{equation}
```

Finally, we compute the eigenvalues of the companion matrix to recover the (approximate) roots of the polynomial:

```{=latex}
\begin{equation*}
    \lambda( \Matrix{C} ) \approx [ -3.70928, -1.19394, 0.903212, 3]
\end{equation*}
```

```{matlab}
function [eigvals, ritz] = ComputeEigenvalues( A, tol, maxiter )
  num_digits = ceil( log10( 1/tol ) );
  ritz = sym( zeros( size( A, 1 ), maxiter + 1 ) );
  ritz(:,1) = diag( A );
  for iter = 1 : maxiter
    [Q, R] = qr( A );
    A = vpa( R * Q, num_digits );
    ritz(:,iter+1) = diag( A );
    if norm( ritz(:,iter+1) - ritz(:, iter), inf ) <= tol
      break
    end
  end
  ritz(:, iter+2 : end) = [];
  eigvals = ritz(:, end);
end
```

```{matlab}
x = sym( "x" );
polynomial = (1/2)*x^4 + (1/2)*x^3 - 6*x^2 - 2*x^1 + 6*x^0
monic_polynomial = PolynomialToMonic( polynomial )
C = CompanionMatrix( polynomial )
[eigvals, ritz] = ComputeEigenvalues( C, 1e-12, 1e3 );
eigvals = vpa( sort( eigvals ), 4 )
```

We can plot the polynomial and its roots to visually confirm that this approach has, in fact, found the polynomial's roots.

```{matlab}
%| echo: false
eig_center = mean( [ min( eigvals ), max( eigvals ) ] );
eig_range = range( eigvals );
domain = eig_center * ones( 1, 2 ) + 1.2 * [ -eig_range, eig_range ]/2;

figure
hold on
fplot( polynomial, double( domain ), LineWidth=2 )
scatter( eigvals, zeros( size( eigvals ) ), MarkerFaceColor="k", MarkerEdgeColor="k" )
ax = gca;
ax.XAxisLocation = "origin";
```

```{matlab}
function eigvals = PolynomialRoots( polynomial )
  C = CompanionMatrix( polynomial )
  eigvals = ComputeEigenvalues( C, 1e-16, 1e3 );
  [~, sidx] = sort( eigvals );
  eigvals = eigvals( sidx );
end
```

## A Footnote

Finally, let's take a moment to make a quick observation and comment.
You may be aware that there are no closed-form equations, using only elementary arithmetic operations and fractional powers, for computing the roots of polynomials greater than degree-4[^1].
Consider that, if there existed an algorithm for computing exact eigenvalues in a finite number of steps for matrices of size $5\times5$ (corresponding to characteristic polynomials of degree-5) or larger, that then we would have an equation for finding roots of polynomials greater than degree-4.
This is why, in practical finite element codes, eigenvalue extraction methods are all approximate iterative methods[^2].
In this demonstration we used an iterative method based on QR factorization.

```pseudocode
#| html-indent-size: "1.2em"
#| html-comment-delimiter: "//"
#| html-line-number: true
#| html-line-number-punc: ":"
#| html-no-end: false
#| pdf-placement: "htb!"
#| pdf-line-number: true

\begin{algorithm}
  \caption{Computing Eigenvalues via $\Matrix{QR}$ Factorization }
  \begin{algorithmic}
    \Procedure{ComputeEigenvalues}{$\Matrix{A}^{n \times n}$, tol, maxit}
      \State $\tilde{\lambda}_0 = \Vector{0}^{n,1}$
      \For{ $i \in \{1, \dots, \mathrm{maxit}\}$ }
        \State $\Matrix{Q}, \Matrix{R} = $ \Call{Factorize}{$\Matrix{A}$, method='qr'}
        \State $\Matrix{A} = \Matrix{R} \Matrix{Q}$
        \State $\tilde{\lambda}_{i} = \mathrm{diag}(\Matrix{A})$
        \If{$\| \tilde{\lambda}_{i} - \tilde{\lambda}_{i-1} \|_{\infty} \leq \mathrm{tol}$}
          \State \textbf{break}
        \EndIf
      \EndFor
      \State \Return{$\tilde{\lambda}_{i}$}
    \EndProcedure
  \end{algorithmic}
\end{algorithm}
```

Note that, in this algorithm, we use the notation $\tilde{\lambda}$ to denote that the values are only an approximation of the true eigenvalues, $\lambda$.
These converging approximations are often called *Ritz values*.
We can plot the convergence of the Ritz values towards the true eigenvalues:

```{matlab}
%| echo: false
[~, sidx] = sort( ritz(:,end) );
sorted_ritz = ritz(sidx, :);

figure
hold on
for ii = 1 : size( ritz, 1 )
  plot( sorted_ritz(ii,:), LineWidth=2, DisplayName="$\tilde{\lambda}_" + num2str(ii) + "$" )
end
xlabel( "Iteration" )
legend()

true_eig = vpa( sort( vpa( eig( C ), 32 ) ), 32 );
figure
hold on
for ii = 1 : size( sorted_ritz, 1 )
  err = abs( ( sorted_ritz(ii, :) - true_eig(ii) ) );
  plot( err, LineWidth=2, DisplayName="$\tilde{\lambda}_" + num2str(ii) + "$" )
end
xlabel( "Iteration" )
ylabel( "$ \| \tilde{\lambda}_{\mathrm{i}} - \lambda_{\mathrm{i}} \| $" )
legend()

ax = gca;
ax.XScale = "linear";
ax.YScale = "log";
ax.YGrid = "on";
ax.YMinorGrid = "on";
```

[^1]: This is the [Abel-Ruffini theorem](https://en.wikipedia.org/wiki/Abel%E2%80%93Ruffini_theorem).
Of course, for some polynomials of degree greater than four we can write such equations, such as $x^{100}$ , but this is not possible *in general*.
[^2]:  Such as the power method, Arnoldi method, Lancoz method, QR algorithm, LOBPCG